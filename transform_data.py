import numpy as np
from sentence_transformers import SentenceTransformer, util
from code_sup import VALID_DDD, months, month_translation
import pandas as pd
import re
from dateutil import parser
from rapidfuzz import process
import time

#---------------------------IDENTIFICAR PLANILHA---------------------------#
def classificar_df(df) -> str:
    """
    Classifica um DataFrame de acordo com suas colunas.

    Retorna:
        - "Pessoa" se contiver as colunas "rg" e "cpf".
        - "Empresa" se contiver as colunas "cnpj" e "cnae".
        - "NegÃ³cio" se contiver as colunas "temperatura" e "propriedade".
        - "Desconhecido" se nÃ£o atender a nenhum dos critÃ©rios.
    """

    criterios = {
        "Pessoa": {"rg", "cpf"},
        "Empresa": {"cnpj", "cnae"},
        "NegÃ³cio": {"temperatura", "propriedade"}
    }

    # Criar um conjunto temporÃ¡rio de colunas formatadas, sem alterar o df original
    colunas_formatadas = {re.sub(r'\W+', '', col).lower() for col in df.columns}

    for categoria, colunas_necessarias in criterios.items():
        if colunas_necessarias.issubset(colunas_formatadas):
            return categoria

    return "Desconhecido"

def dd_list_columns(df):
    # Identificar colunas que terminam com " (lista)"
    dd_lists = [col for col in df.columns if col.endswith(" (lista)")]

    # Criar uma lista com os nomes sem o sufixo
    cleaned_dd_names = [col.replace(" (lista)", "") for col in dd_lists]

    # Criar um dicionÃ¡rio de mapeamento
    rename_dd_columns = dict(zip(dd_lists, cleaned_dd_names))

    # Renomear colunas no DataFrame
    df.rename(columns=rename_dd_columns, inplace=True)

    return df, cleaned_dd_names

#---------------------------AVALIAR COLUNAS E IDENTIFICAR TIPO---------------------------#

def detect_date_format(date_series):
    """
    Analisa uma coluna de datas para determinar se o formato mais comum Ã© DD/MM/YYYY ou MM/DD/YYYY.
    Retorna 'dayfirst' como True se for DD/MM/YYYY, False se for MM/DD/YYYY.
    """
    dd_count = 0
    mm_count = 0

    for date in date_series.dropna():
        match = re.match(r"(\d{1,2})[-/.](\d{1,2})[-/.](\d{2,4})", str(date))
        if match:
            first, second, _ = map(int, match.groups())
            if first > 12:
                dd_count += 1
            elif second > 12:
                mm_count += 1

    if dd_count > mm_count:
        return True
    elif mm_count > dd_count:
        return False
    else:
        return True


def is_potential_date(value):
    """Verifica se um valor pode ser uma data, analisando se contÃ©m separadores ou nomes de meses."""
    value_str = str(value)

    if re.search(r"[-/.]", value_str):
        return True

    if re.search(months, value_str, re.IGNORECASE):
        return True

    return False

def replace_months(value):
    """Substitui os meses em portuguÃªs por inglÃªs para facilitar a conversÃ£o de datas."""
    match = re.search(months, value, re.IGNORECASE)
    if match:
        pt_month = match.group(0)  # Nome do mÃªs encontrado
        en_month = month_translation.get(pt_month.lower(), pt_month)  # Traduz se possÃ­vel
        value = value.replace(pt_month, en_month)
    return value


def is_date(value, dayfirst=True):
    """Tenta converter um valor para datetime, retornando True se for possÃ­vel."""
    value_str = str(value).strip()

    if value_str.isdigit() and len(value_str) == 4:
        year = int(value_str)
        return 1900 <= year <= 2100

    if not re.search(r"[-/.]", value_str) and not re.search(months, value_str, re.IGNORECASE):
        return False

    try:
        value_str = replace_months(value_str)  # Aplicando a substituiÃ§Ã£o antes da conversÃ£o
        parsed = parser.parse(value_str, dayfirst=dayfirst)
        if 1900 <= parsed.year <= 2100:
            return True
        return False
    except (ValueError, TypeError):
        return False


def convert_to_standard_date(value, dayfirst=True):
    """Converte qualquer formato de data para o formato dd/mm/aaaa garantindo a interpretaÃ§Ã£o correta."""
    try:
        value = replace_months(value)  # Aplicando a substituiÃ§Ã£o antes da conversÃ£o
        parsed_date = parser.parse(value, dayfirst=dayfirst)
        formatted_date = parsed_date.strftime('%d/%m/%Y')
        return formatted_date
    except (ValueError, TypeError):
        return value


def detect_and_format_dates(df, detected_types):
    print("ğŸ” Detectando e formatando colunas de data...")
    for col in df.columns:

        non_empty = df[col].dropna()
        non_empty = non_empty[non_empty.astype(str).str.strip() != '']

        potential_dates = non_empty.astype(str).apply(is_potential_date).sum()

        if potential_dates < len(non_empty) * 0.9:
            continue

        is_date_valid = non_empty.astype(str).apply(lambda x: is_date(x, dayfirst=True)).mean()

        if is_date_valid > 0.9:
            dayfirst_setting = detect_date_format(non_empty)
            print(f"â€¢ Coluna '{col}' identificada como 'Data' e serÃ¡ convertida.")

            df[col] = df[col].astype('object')
            df.loc[non_empty.index, col] = non_empty.astype(str).apply(
                lambda x: convert_to_standard_date(x, dayfirst=dayfirst_setting))

            detected_types[col] = "Data"

    return df


def detect_address(df, detected_types, threshold=0.8):
    print("\nğŸ” Detectando colunas de endereÃ§o...")
    def is_address(text):
        """
        Evaluates whether a given text is likely to be an address.
        Returns True if it matches address patterns, otherwise False.
        """
        if not isinstance(text, str) or len(text) < 5:
            return False  # Ignore invalid or too short strings

        # Common address keywords
        street_pattern = r'\b(Rua|Av\.?|Avenida|Rodovia|Estrada|PraÃ§a|Travessa|Alameda|R\.)\b'
        number_pattern = r'\b\d{1,5}\b'  # Numbers (addresses often have numbers)
        cep_pattern = r'\b\d{5}-\d{3}\b'  # Brazilian postal code format (CEP)
        uf_pattern = r'\b[A-Z]{2}\b'  # State abbreviation (SP, RJ, etc.)
        neighborhood_city_pattern = r'[-,]\s*[A-Za-zÃ€-Ã¿\s]+'

        score = 0

        # Check for street-related words
        if re.search(street_pattern, text, re.IGNORECASE):
            score += 0.3

        # Check for numbers
        if re.search(number_pattern, text):
            score += 0.2

        # Check for CEP
        if re.search(cep_pattern, text):
            score += 0.2

        # Check for State (UF)
        if re.search(uf_pattern, text):
            score += 0.1

        # Check for neighborhood or city patterns
        if re.search(neighborhood_city_pattern, text):
            score += 0.2

        return score >= 0.5  # Considera endereÃ§o se a pontuaÃ§Ã£o for 0.5 ou mais

    for col in df.columns:
        valid_count = df[col].dropna().astype(str).apply(is_address).sum()  # Conta quantas linhas sÃ£o endereÃ§os
        total_count = df[col].notna().sum()  # Conta total de valores nÃ£o nulos

        if total_count > 0 and (
                valid_count / total_count) >= threshold:  # Verifica se >= 80% das linhas sÃ£o endereÃ§os
            print(f"â€¢ Coluna '{col}' identificada como EndereÃ§o.")
            detected_types[col] = "EndereÃ§o"

    return detected_types

def detect_finance(df, detected_types, threshold=0.8):
    print("\nğŸ” Detectando colunas de valores monetÃ¡rios e ranges de valores...")

    def is_financial(text):
        if not isinstance(text, str) or len(text) < 2:
            return False, False  # Retorna duas flags: (Ã© valor simples, Ã© range)

        # Se o valor for um nÃºmero puro e tiver muitos dÃ­gitos, assume que Ã© um ID
        if text.isdigit() and len(text) >= 9:
            return False, False  # Provavelmente um ID, nÃ£o dinheiro

        # Se o valor for uma probabilidade (entre 0 e 1), nÃ£o Ã© dinheiro
        try:
            num_value = float(text.replace(",", "."))  # Converter para float
            if 0 <= num_value <= 1:
                return False, False  # Provavelmente uma probabilidade
        except ValueError:
            pass  # Se der erro, continua a verificaÃ§Ã£o normal

        # SÃ­mbolos de moeda e palavras numÃ©ricas
        currency_symbols = r'(R\$|\$|BRL|USD|â‚¬|Â£|Â¥|CAD|AUD)'  # Moedas comuns
        word_numbers = r'(\bmilhÃ£o\b|\bbilhÃ£o\b|\bmilhÃµes\b|\bbilhÃµes\b|\bmil\b)'  # "milhÃ£o", "bilhÃ£o", etc.

        # PadrÃ£o para nÃºmeros formatados (ex: 1.000.000,00 ou 1,000,000.00)
        number_pattern = r'(\d{1,3}(\.\d{3})*,\d{2}|\d{1,3}(,\d{3})*\.\d{2})'

        # PadrÃ£o para nÃºmeros escritos por extenso (ex: "10 milhÃµes", "100 bilhÃµes")
        word_number_pattern = r'(\d+)\s*(milhÃ£o|milhÃµes|bilhÃ£o|bilhÃµes|mil)'

        # Indicadores de intervalo: "-" ou palavras como "atÃ©"
        range_indicators = r'(-|\+|\batÃ©\b|\be\b)'  # "AtÃ© 360.000", "360.000 - 4.800.000", etc.

        # VerificaÃ§Ãµes
        has_currency = bool(re.search(currency_symbols, text, re.IGNORECASE))
        has_word_number = bool(re.search(word_numbers, text, re.IGNORECASE))
        has_formatted_number = bool(re.search(number_pattern, text))
        has_range_indicator = bool(re.search(range_indicators, text, re.IGNORECASE))
        has_number_by_words = bool(re.search(word_number_pattern, text))

        # Se tem moeda ou palavra numÃ©rica + nÃºmero, Ã© valor financeiro
        is_value = (has_currency or has_word_number or has_number_by_words) and (
                    has_formatted_number or has_number_by_words)

        # Se tambÃ©m tem um indicador de intervalo, Ã© um range de valores
        is_range = is_value and has_range_indicator

        return is_value, is_range

    for col in df.columns:
        if col in detected_types:
            continue  # Pula colunas jÃ¡ processadas

        # Se a coluna Ã© numÃ©rica e o nome tem as palavras 'valor', 'receita', 'faturamento', Ã© considerada "Valor"
        # Lista de palavras-chave indicativas de valor monetÃ¡rio
        keywords = ['valor', 'receita', 'faturamento']

        # Verifica se o nome da coluna contÃ©m alguma dessas palavras
        col_lower = col.lower()
        has_keyword = any(kw in col_lower for kw in keywords)

        # Verifica se 90% dos valores nÃ£o nulos sÃ£o compostos apenas por dÃ­gitos
        def is_valid_number_format(text):
            if not isinstance(text, str):
                return False

            text = text.strip()
            if text.count('.') > 1 or text.count(',') > 1:
                return False

            if not re.fullmatch(r'[\d.,]+', text):
                return False

            return True

        # Verifica se os valores batem com padrÃ£o de nÃºmero formatado
        is_numeric_like = df[col].dropna().astype(str).apply(is_valid_number_format).mean() > 0.9

        # Verifica se os valores sÃ£o sÃ³ dÃ­gitos (ex: "123456")
        is_numeric = df[col].dropna().astype(str).apply(str.isdigit).mean() > 0.9

        if has_keyword and (is_numeric_like or is_numeric):
            if col == 'Valor':
                print(f"Coluna '{col}': is numerica like - {is_numeric_like}, is numeric - {is_numeric}")
                print(df[col].head())
            detected_types[col] = "Valor"
            print(f"âœ” Coluna '{col}' automaticamente classificada como 'Valor' (baseado em nome e conteÃºdo).")
            continue

        valid_values = df[col].dropna().astype(str).apply(is_financial)
        total_count = df[col].notna().sum()

        value_count = sum(1 for v, r in valid_values if v and not r)  # Apenas valores simples
        range_count = sum(1 for v, r in valid_values if r)  # Apenas ranges de valores

        if col == 'Valor':
            print(f"Coluna '{col}': valid values - {valid_values}, total count - {total_count}, value count - {value_count}")
            print(df[col].head())

        if total_count > 0:
            value_ratio = value_count / total_count
            range_ratio = range_count / total_count

            if range_ratio >= threshold:
                print(f"â€¢ Coluna '{col}' identificada como Range de Valores.")
                detected_types[col] = "Range de valores"
            elif value_ratio >= threshold:
                print(f"â€¢ Coluna '{col}' identificada como Valor MonetÃ¡rio.")
                detected_types[col] = "Valor"

    return detected_types

def detect_num_range(df, detected_types, threshold=0.8):
    print("\nğŸ” Detectando colunas de range de nÃºmeros...")

    def is_num_range(text):
        """
        Avalia se um dado representa um nÃºmero simples ou um range.
        Retorna True se for um nÃºmero e True se for um range.
        """
        if not isinstance(text, str) or len(text) < 2:
            return False, False  # Retorna duas flags: (Ã© nÃºmero, Ã© range)

        # PadrÃµes de intervalos numÃ©ricos vÃ¡lidos:
        pattern_range = r'^\d+\s*(-|\batÃ©\b)\s*\d+$'  # "10-20", "100 atÃ© 200", "50 - 100"
        pattern_open_range = r'^\b(atÃ©)\s+\d+$'  # "atÃ© 300"
        pattern_plus = r'^\d+\s*\+$'  # "5+"
        float_pattern = r'^-?\d+([.,])\d+$'  # Float simples, ex: "12.3" ou "8,9"

        try:
            has_int_number = int(text)  # Se for um nÃºmero inteiro vÃ¡lido, nÃ£o gera erro
            # has_int_number = True
        except ValueError:
            has_int_number = False  # Se der erro ao converter para int, nÃ£o Ã© nÃºmero inteiro

        has_float_number = bool(re.search(float_pattern, text))
        has_pattern_range = bool(re.search(pattern_range, text, re.IGNORECASE))
        has_pattern_open_range = bool(re.search(pattern_open_range, text, re.IGNORECASE))
        has_pattern_plus = bool(re.search(pattern_plus, text, re.IGNORECASE))

        # Se tem separador de nÃºmeros, sinal de "+" ou "atÃ©" - Ã© um range
        is_range = has_pattern_range or has_pattern_open_range or has_pattern_plus

        # Se tem nÃºmeros inteiros ou float
        is_number = has_int_number or has_float_number

        return is_number, is_range

    for col in df.columns:
        if col in detected_types:
            continue  # Pula colunas jÃ¡ processadas
        # print(f"Coluna sendo avaliada: {col}")
        valid_values = df[col].dropna().astype(str).apply(is_num_range)
        total_count = df[col].notna().sum()

        number_count = sum(1 for v, r in valid_values if v)  # Apenas nÃºmeros
        range_count = sum(1 for v, r in valid_values if r)  # Apenas ranges de nÃºmeros

        if total_count > 0:
            range_ratio = range_count / total_count
            number_ratio = number_count / total_count
            # print(f"Range ratio: {range_ratio}")
            # print(f"Number ratio: {number_ratio}")

            if range_ratio >= threshold or ((range_ratio >= threshold * 0.35) and (range_ratio + number_ratio >= (threshold * 1.1))):
                print(f"â€¢ Coluna '{col}' identificada como Range de NÃºmeros.")
                detected_types[col] = "NÃºmero (range)"

    return detected_types

def transform_percent(df, threshold=0.8):
    percent_pattern = re.compile(r'^\s*(\d+[.,]?\d*)\s*%\s*$')
    mod_columns = []

    for coluna in df.columns:
        valores = df[coluna].dropna()  # Remove valores NaN para anÃ¡lise
        total = len(valores)
        if total == 0:
            continue

        percent_amount = sum(bool(percent_pattern.match(str(valor))) for valor in valores)
        percent_prop = percent_amount / total

        if percent_prop >= threshold:
            mod_columns.append(coluna)

            # Converter para formato decimal
            def convert_decimal(valor):
                match = percent_pattern.match(str(valor))
                if match:
                    numero = match.group(1).replace(',', '.')  # Substitui ',' por '.' para conversÃ£o correta
                    return float(numero) / 100  # Converte para decimal
                return None  # MantÃ©m NaN para valores invÃ¡lidos

            df[coluna] = df[coluna].apply(convert_decimal)

    return df

def format_phone(value):
    if isinstance(value, str):
        if len(value) == 11:
            return f'+55 ({value[:2]}) {value[2:7]}-{value[7:]}'
        elif len(value) == 10:
            return f'+55 ({value[:2]}) {value[2:6]}-{value[6:]}'
        elif len(value) == 12:
            return f'+{value[:2]} ({value[2:4]}) {value[4:8]}-{value[8:]}'
        elif len(value) == 13:
            return f'+{value[:2]} ({value[2:4]}) {value[4:9]}-{value[9:]}'

        else:
            print("Falha ao formatar telefone - nÃºmero de caracteres nÃ£o bate")
            return None
    else:
        print(f"Falha ao formatar telefone na coluna {value} - falha ao identificar dado")
        return None

def format_cpf(value):
    if isinstance(value, str):
        if len(value) == 11:
            return f'{value[:3]}.{value[3:6]}.{value[6:9]}-{value[9:]}'
        else:
            print(f"NÃ£o foi possÃ­vel formatar o cpf - nÃ£o tem 11 caracteres")
            return None
    else:
        print("NÃ£o foi possÃ­vel formatar o cpf - falha ao identificar dado")
        return None

def format_cnpj(value):
    if isinstance(value, str):
        digits = re.sub(r'\D', '', value)  # Remove qualquer caractere que nÃ£o seja nÃºmero
        if len(digits) == 14:
            return f'{digits[:2]}.{digits[2:5]}.{digits[5:8]}/{digits[8:12]}-{digits[12:]}'
        else:
            print("NÃ£o foi possÃ­vel formatar o CNPJ - nÃ£o tem 14 caracteres")
            return None
    else:
        print("NÃ£o foi possÃ­vel formatar o CNPJ - falha ao identificar dado")
        return None

def format_cnae(value):
    if isinstance(value, str):
        digits = re.sub(r'\D', '', value)  # Remove qualquer caractere que nÃ£o seja nÃºmero
        if len(digits) == 7:
            return f'{digits[:2]}.{digits[2:4]}-{digits[4]}/{digits[5:]}'
        else:
            print("NÃ£o foi possÃ­vel formatar o CNAE - nÃ£o tem 7 caracteres")
            return None
    else:
        print("NÃ£o foi possÃ­vel formatar o CNAE - falha ao identificar dado")
        return None

def format_value(value):
    if isinstance(value, (int, float)):
        return str(int(value))  # Se jÃ¡ for nÃºmero, retorna como string

    if not isinstance(value, str):
        return value  # Se nÃ£o for string, retorna sem alteraÃ§Ãµes

    # Verifica se hÃ¡ palavras indicando magnitude numÃ©rica (mil, milhÃ£o, bilhÃ£o)
    word_number_match = re.search(r'(\d+)\s*(milhÃ£o|milhÃµes|bilhÃ£o|bilhÃµes|mil)', value, re.IGNORECASE)

    if word_number_match:
        num = int(word_number_match.group(1))  # ObtÃ©m o nÃºmero antes da palavra
        multiplier = word_number_match.group(2).lower()  # ObtÃ©m a palavra (mil, milhÃ£o, bilhÃ£o)

        # Define o multiplicador correspondente
        if "milhÃ£o" in multiplier or "milhÃµes" in multiplier:
            num *= 1_000_000
        elif "bilhÃ£o" in multiplier or "bilhÃµes" in multiplier:
            num *= 1_000_000_000
        elif "mil" in multiplier:
            num *= 1_000

        return str(num)  # Retorna o nÃºmero corrigido como string

    # Remover sÃ­mbolos de moeda, letras e espaÃ§os
    value = re.sub(r'[^\d.,]', '', value)  # MantÃ©m apenas nÃºmeros, pontos e vÃ­rgulas

    # Se for um nÃºmero inteiro puro (ex: "450000"), retorna apenas o nÃºmero
    if value.isdigit():
        return value

    # Se o formato for americano (ex: "260,000.00"), converter para o formato correto
    if re.search(r'\d{1,3},\d{3}\.\d{2}', value):
        value = value.replace(',', '').split('.')[0]  # Remove ',' e corta os centavos

    # Se for um nÃºmero no formato brasileiro (ex: "1.000.000,00"), remover pontuaÃ§Ã£o e centavos
    if re.match(r'^\d{1,3}(\.\d{3})*,\d{2}$', value):
        value = value.rsplit(',', 1)[0]  # Remove a parte decimal (centavos)
        value = value.replace('.', '')  # Remove pontos dos milhares

    return value  # Retorna o nÃºmero formatado

def is_valid_cpf(value):
    """Verifica se um valor Ã© um CPF vÃ¡lido seguindo o algoritmo da Receita Federal."""
    digits = re.sub(r'\D', '', str(value))

    if len(digits) != 11 or digits == digits[0] * 11:
        return None

    sum1 = sum(int(digits[i]) * (10 - i) for i in range(9))
    digit1 = (sum1 * 10) % 11
    digit1 = 0 if digit1 >= 10 else digit1

    sum2 = sum(int(digits[i]) * (11 - i) for i in range(10))
    digit2 = (sum2 * 10) % 11
    digit2 = 0 if digit2 >= 10 else digit2

    return "CPF" if digits[-2:] == f"{digit1}{digit2}" else None


# FunÃ§Ã£o corrigida para validar CNPJ
def is_valid_cnpj(value):
    """Verifica se um valor Ã© um CNPJ vÃ¡lido seguindo o algoritmo da Receita Federal."""
    digits = re.sub(r'\D', '', str(value))

    if len(digits) != 14 or digits == digits[0] * 14:
        return None

    def calcular_digito(base):
        pesos = [5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2] if len(base) == 12 else [6, 5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]
        soma = sum(int(base[i]) * pesos[i] for i in range(len(base)))
        resto = soma % 11
        return '0' if resto < 2 else str(11 - resto)

    base_cnpj = digits[:12]
    digito1 = calcular_digito(base_cnpj)
    digito2 = calcular_digito(base_cnpj + digito1)

    return "CNPJ" if digits[-2:] == f"{digito1}{digito2}" else None

def is_valid_cnae(value):
    """Verifica se um valor Ã© um cÃ³digo CNAE vÃ¡lido."""
    digits = re.sub(r'\D', '', str(value))
    return "CNAE" if len(digits) == 7 else None  # CNAE tem 7 dÃ­gitos

def is_phone_number(value):
    """Verifica se um valor Ã© um nÃºmero de telefone vÃ¡lido considerando apenas o DDI do Brasil (55)."""
    digits = re.sub(r'\D', '', str(value))

    if len(digits) in [10, 11]:
        ddd, phone_number = digits[:2], digits[2:]
        if ddd in VALID_DDD and ((len(digits) == 10 and re.match(r'^[2-5]\d{7}$', phone_number)) or
                                 (len(digits) == 11 and re.match(r'^9\d{8}$', phone_number))):
            return "Telefone"
    elif len(digits) in [12, 13]:
        ddi, ddd, phone_number = digits[:2], digits[2:4], digits[4:]
        if ddi == "55" and ddd in VALID_DDD:
            if len(digits) == 12 and re.match(r'^[2-5]\d{7}$', phone_number):
                return "Telefone"
            elif len(digits) == 13 and re.match(r'^9\d{8}$', phone_number):
                return "Telefone"

    return None

def detect_identifiers(df, detected_types):
    """
    Detecta se as colunas do DataFrame contÃªm emails, LinkedIn, Instagram, Sites, CPF, CNPJ. CNAE ou Telefone.
    Se mais da metade dos valores forem de um tipo especÃ­fico, a coluna serÃ¡ categorizada.
    """
    print("\nğŸ” Detectando colunas de identificadores: \nâ†’ Site, E-mail, LinkedIn, Instagram\nâ†’ CPF, CNPJ, CNAE, Telefone")

    # ExpressÃµes regulares para identificaÃ§Ã£o
    patterns = {
        "E-mail": re.compile(r'^[\w.-]+@[\w.-]+\.\w{2,}$'),
        "Linkedin": re.compile(r'^(https?://)?(www\.)?linkedin\.com/in/[^/]+/?$'),
        "Instagram": re.compile(r'^(@[\w.]+|https?://(www\.)?instagram\.com/[^/]+/?)$'),
        "Site": re.compile(r'^(https?://)?(www\.)?[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}(/.*)?$')
    }

    for col in df.columns:
        if col not in detected_types and df[col].dtype == 'object':
            values = df[col].dropna().astype(str).str.strip()  # Remove espaÃ§os invisÃ­veis

            total_values = len(values)
            if total_values == 0:
                continue  # Pula colunas vazias

            # Contagem de correspondÃªncias para expressÃµes regulares
            regex_matches = {key: values.str.match(patterns[key]).sum() for key in patterns}

            # Contagem de validaÃ§Ãµes personalizadas
            # print("\nğŸ“Š Exemplo de valores na coluna CNPJ antes da validaÃ§Ã£o:")
            # print(df["CNPJ"].head(10).tolist())  # Mostra os primeiros 10 CPFs na lista

            cpf_results = values.apply(is_valid_cpf)
            phone_results = values.apply(is_phone_number)
            cnpj_results = values.apply(is_valid_cnpj)
            cnae_results = values.apply(is_valid_cnae)

            cpf_matches = cpf_results.eq("CPF").sum()
            phone_matches = phone_results.eq("Telefone").sum()
            cnpj_matches = cnpj_results.eq("CNPJ").sum()
            cnae_matches = cnae_results.eq("CNAE").sum()

            # Debug para verificar os valores retornados
            # print(f"Resultados CNPJ para a coluna '{col}':\n{cnpj_results.value_counts()}")
            # print(f"Coluna {col}: CNPJ count: {cnpj_matches}, total: {total_values}")

            # Combinar todas as contagens
            matches = {**regex_matches, "CPF": cpf_matches, "Telefone": phone_matches,
                       "CNPJ": cnpj_matches, "CNAE": cnae_matches}

            # Verifica qual categoria tem mais de 80% de correspondÃªncia
            for tipo, count in matches.items():
                # print(f"Coluna {col}: count: {count}, total: {total_values}")
                if count / total_values > 0.8:
                    detected_types[col] = tipo
                    print(f"â€¢  Coluna '{col}' identificada como {tipo}.")
                    break  # Se uma categoria for detectada, nÃ£o precisa verificar as outras

    return detected_types

def format_df(df, detected_types):
    """Remove caracteres nÃ£o alfanumÃ©ricos de todas as colunas nÃ£o identificadas anteriormente."""
    print("\nğŸ” Formatando colunas - fazendo alteraÃ§Ãµes necessÃ¡rias...")

    def clean_column(value):
        if isinstance(value, str):
            if not value.strip():
                return value  # Retorna o valor sem alteraÃ§Ãµes se for vazio ou conter sÃ³ espaÃ§os
            return re.sub(r'\D', '', value)
        return value

    # Criar uma cÃ³pia do DataFrame para evitar modificar o original
    df_formated = df.copy()

    format_columns = [
        col for col in df_formated.select_dtypes(include=["object"]).columns
        if detected_types.get(col, "") in ("Telefone", "CPF", "CNPJ", "CNAE")  # Retorna "" se col nÃ£o existir
    ]

    format_value_columns = [
        col for col in df_formated.select_dtypes(include=["object"]).columns
        if detected_types.get(col, "") == "Valor"
    ]

    format_range_columns = [
        col for col in df_formated.select_dtypes(include=["object"]).columns
        if detected_types.get(col, "") == "Range de valores"
    ]

    # Aplicar a formataÃ§Ã£o apenas nessas colunas
    print("Formatando colunas de identificadores...")
    for col in format_columns:
        # Primeiro, aplica uma limpeza nos textos
        df_formated[col] = df_formated[col].map(clean_column)
        # Em seguida, formata de acordo com o tipo detectado
        if detected_types.get(col, "") == "Telefone":
            df_formated[col] = df_formated[col].map(format_phone)
        elif detected_types.get(col, "") == "CPF":
            df_formated[col] = df_formated[col].map(format_cpf)
        elif detected_types.get(col, "") == "CNPJ":
            df_formated[col] = df_formated[col].map(format_cnpj)
        elif detected_types.get(col, "") == "CNAE":
            df_formated[col] = df_formated[col].map(format_cnae)

    print("Formatando colunas de valores...")
    for col in format_value_columns:
        df_formated[col] = df_formated[col].map(format_value)
        # print(f"Coluna {col}: \n{df_formated[col]}")

    print("Formatando colunas com range de valores...")
    for col in format_range_columns:
        detected_types[col] = "Valor (range)"

    print(f"âœ… Colunas formatadas: {format_columns}, {format_value_columns}")

    return df_formated

def detect_column_type(df, detected_types):
    """Define tipos de coluna restantes como 'NÃºmero', 'NÃºmero com erro' ou 'Texto'.
       Para colunas de texto, retorna uma lista de valores Ãºnicos conforme a proporÃ§Ã£o especificada."""

    print("\nğŸ” Detectando colunas restantes como nÃºmero ou texto...")

    unique_values_dict = {}
    left_categories = {"Null", "NÃºmero", "NÃºmero com erro", "Texto"}

    for col in df.columns:
        if col not in detected_types:
            # Primeiro verifica se a coluna estÃ¡ completamente vazia
            if df[col].dropna().empty:
                detected_types[col] = "Null"
                continue

            # Verifica se todos os valores nÃ£o-nulos contÃªm apenas dÃ­gitos
            all_numeric = df[col].dropna().apply(lambda x: str(x).isdigit()).all()

            numeric_ratio = df[col].dropna().apply(lambda x: str(x).isdigit()).mean()

            if all_numeric:
                detected_types[col] = "NÃºmero"
            elif numeric_ratio >= 0.95:  # Ajuste aqui conforme necessÃ¡rio
                detected_types[col] = "NÃºmero com erro"
            else:
                detected_types[col] = "Texto"

        # AnÃ¡lise adicional para colunas de texto
        if detected_types[col] == "Texto" or detected_types[col].endswith(" (range)"):
            unique_values = df[col].dropna().unique()  # ObtÃ©m valores Ãºnicos, excluindo NaN

            unique_values_dict[col] = unique_values.tolist()

    for col, col_type in detected_types.items():
        if col_type in left_categories:
            print(f"â€¢ Coluna '{col}' identificada como {col_type}.")

    return detected_types, unique_values_dict

def correct_number(df, detected_types):
    for col in df.columns:
        if detected_types.get(col) == "NÃºmero com erro":
            print(f"ğŸ”§ Corrigindo coluna '{col}'...")

            # Remove todos os caracteres nÃ£o numÃ©ricos
            df[col] = df[col].astype(str).apply(lambda x: re.sub(r'\D', '', x))

            # Converte a coluna para tipo numÃ©rico, substituindo strings vazias por NaN
            df[col] = pd.to_numeric(df[col], errors='coerce')

            # Atualiza o tipo detectado para 'NÃºmero'
            detected_types[col] = "NÃºmero"

            print(f"âœ… Coluna '{col}' corrigida e atualizada para o tipo 'NÃºmero'.")

    return df, detected_types

def analyze_table(df, filename):
    """Executa todas as etapas na sequÃªncia correta."""
    print(f"\nAnalisando dados em: {filename}\n")

    # Configura pandas para exibir todas as colunas na saÃ­da
    # pd.set_option('display.max_columns', None)  # Exibe todas as colunas
    # pd.set_option('display.width', 200)  # Ajusta a largura do terminal para evitar truncamento
    # Configura o pandas para exibir todas as linhas e colunas
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', None)
    pd.set_option('display.expand_frame_repr', False)

    detected_types = {}

    df = detect_and_format_dates(df, detected_types)
    # print(f"\nDF apÃ³s transformar datas: \n{df.head(5).to_string(index=False)}")

    detected_types = detect_address(df, detected_types)

    detected_types = detect_finance(df, detected_types)
    detected_types = detect_identifiers(df, detected_types)
    detected_types = detect_num_range(df, detected_types)

    df = transform_percent(df)
    df = format_df(df, detected_types)
    # print(f"\nDF apÃ³s formataÃ§Ã£o: \n{df.head(5).to_string(index=False)}")

    # Detecta tipos de colunas e obtÃ©m valores Ãºnicos para colunas de texto
    detected_types, unique_values_dict = detect_column_type(df, detected_types)

    # Corrige colunas classificadas como 'NÃºmero com erro'
    df, detected_types = correct_number(df, detected_types)

    print(f"\nDF apÃ³s formataÃ§Ã£o: \n{df.head(5).to_string(index=False)}")

    result_df = pd.DataFrame(list(detected_types.items()), columns=['Coluna', 'Tipo'])
    print(f"\n{result_df}\n")
    print(df)

    return df, result_df, unique_values_dict

#---------------------------FAZER O MATCH DAS COLUNAS---------------------------#
def extract_year(value):
    """Extrai os Ãºltimos 4 nÃºmeros da string como ano, se possÃ­vel."""
    match = re.search(r'(\d{4})$', str(value))  # Procura um conjunto de 4 nÃºmeros no final
    return int(match.group(1)) if match else None  # Converte para inteiro ou retorna None

def date_var(formated_new, min_valid_percent=0.8):
    """
        Processa uma Series de datas normalizadas (contendo apenas dÃ­gitos no formato DDMMYYYY)
        e retorna a variaÃ§Ã£o (em dias) entre datas consecutivas.

        ParÃ¢metros:
          formated_new: Series com valores de datas contendo apenas dÃ­gitos.
          min_valid_percent: Percentual mÃ­nimo de dados vÃ¡lidos para continuar a operaÃ§Ã£o.
        """

    # ğŸ”¹ 1. Imprimir os dados originais
    # print(f"\nğŸ“Œ Dados originais:\n{formated_new}\n")

    # ğŸ”¹ 2. Remover valores nulos e converter para string
    valid_dates = formated_new.dropna().astype(str)

    # ğŸ”¹ 3. Filtrar apenas os valores que tÃªm exatamente 8 caracteres (DDMMYYYY)
    valid_dates_filtered = valid_dates[valid_dates.str.len() == 8]

    # ğŸ”¹ 4. Verificar a porcentagem de dados vÃ¡lidos
    valid_percent = len(valid_dates_filtered) / len(valid_dates) if len(valid_dates) > 0 else 0

    if valid_percent < min_valid_percent:
        # print(f"âš ï¸ Apenas {valid_percent:.0%} dos dados estÃ£o no formato correto. Abortando operaÃ§Ã£o.")
        return pd.Series(dtype="int64")  # Retorna uma Series vazia

    # print(f"âœ… {valid_percent:.0%} dos dados estÃ£o corretos ({len(valid_dates_filtered)} valores). Continuando...\n")

    # ğŸ”¹ 5. Formatar as datas como DD/MM/YYYY
    valid_dates_filtered = valid_dates_filtered.apply(lambda x: f"{x[:2]}/{x[2:4]}/{x[4:]}")
    # print(f"ğŸ“† Datas formatadas: \n{valid_dates_filtered}\n")

    # ğŸ”¹ 6. Converter para datetime
    valid_dates_filtered = pd.to_datetime(valid_dates_filtered, format="%d/%m/%Y", errors="coerce").dropna()
    # print(f"ğŸ“… Datas convertidas para datetime: \n{valid_dates_filtered}\n")

    # ğŸ”¹ 7. Garantir que seja uma Series e ordenar
    valid_dates_filtered = pd.Series(valid_dates_filtered).sort_values(ignore_index=True)
    # print(f"ğŸ“Œ Datas ordenadas: \n{valid_dates_filtered}\n")

    # ğŸ”¹ 8. Calcular a variaÃ§Ã£o entre valores consecutivos (em dias)
    date_variation = valid_dates_filtered.diff().dt.days
    # print(f"ğŸ“Š VariaÃ§Ã£o entre datas (dias): \n{date_variation}\n")

    return date_variation


def year_evaluation(dates):
    # Extrair os anos da coluna
    data_years = dates.dropna().astype(str).apply(extract_year).dropna()

    # Garantir que as colunas contenham valores inteiros antes de continuar
    if data_years.dtype != 'int64':
        return 0  # Retorna similaridade zero se nÃ£o for possÃ­vel calcular

    # Calcular mÃ©dia e mediana dos anos extraÃ­dos
    data_mean = int(data_years.mean()) if not data_years.empty else 0
    # data_median = int(data_years.median()) if not data_years.empty else 0

    return data_mean

def describe_data_column(col_data, col_name, max_exemplos=5):
    valores = col_data.dropna().astype(str).unique()
    exemplos = sorted(valores)[:max_exemplos]  # sempre os mesmos
    exemplos_str = ", ".join(exemplos)
    return f"Coluna: {col_name}. Tipo: nÃºmero. Exemplos: {exemplos_str}"


def match_columns(ref_data, new_data, ref_types, new_types, filename1, filename2, threshold=0.59):
    match = {}
    not_match_new = set(new_data.columns)
    not_match_ref = set(ref_data.columns)
    candidates = []
    model = SentenceTransformer('paraphrase-MiniLM-L3-v2')
    # model = SentenceTransformer('all-MiniLM-L6-v2')

    # Calcula o embedding de cada coluna
    ref_embeddings = {col: model.encode(col, convert_to_tensor=True) for col in ref_data.columns}
    new_embeddings = {col: model.encode(col, convert_to_tensor=True) for col in new_data.columns}

    # Cria os textos descritivos pra cada coluna, gera embeddings e calcula similaridade semÃ¢ntica entre os dados
    ref_data_desc = {
        col: model.encode(describe_data_column(ref_data[col], col), convert_to_tensor=True)
        for col in ref_data.columns
    }
    new_data_desc = {
        col: model.encode(describe_data_column(new_data[col], col), convert_to_tensor=True)
        for col in new_data.columns
    }

    print("\nIniciando correspondÃªncia de colunas...")

    for ref_col in ref_data.columns:
        for new_col in new_data.columns:
            if new_col in match:
                continue

            ref_embedding = ref_embeddings[ref_col]
            new_embedding = new_embeddings[new_col]

            name_similarity = util.cos_sim(ref_embedding, new_embedding).item()
            # TODO isso nÃ£o deveria considerar

            # Verifica se os tipos de dados sÃ£o compatÃ­veis, ignorando " (range)"
            ref_col_type = ref_types.loc[ref_types['Coluna'] == ref_col, 'Tipo'].values[0] if ref_col in ref_types[
                'Coluna'].values else 'Desconhecido'
            new_col_type = new_types.loc[new_types['Coluna'] == new_col, 'Tipo'].values[0] if new_col in new_types[
                'Coluna'].values else 'Desconhecido'

            # Limpa espaÃ§os e sufixo " (range)" apenas para comparaÃ§Ã£o
            ref_col_type = ref_col_type.strip()
            new_col_type = new_col_type.strip()
            ref_col_type_cleaned = ref_col_type.replace(" (range)", "")
            new_col_type_cleaned = new_col_type.replace(" (range)", "")

            types_compatible = ref_col_type_cleaned == new_col_type_cleaned
            null_types = "Null" in [ref_col_type_cleaned, new_col_type_cleaned]
            if types_compatible or null_types:  # Apenas compara colunas do mesmo tipo e nulas
                #  or value_number
                print(f"{new_col} x {ref_col}: name similarity = {name_similarity:.2f}")

                if name_similarity >= 0.98 and (null_types or ref_col_type.endswith("(range)")): #TODO deixa isso?
                    overall_score = 1.0
                    candidates.append((ref_col, new_col, overall_score))
                    print(
                        f"âœ… Coluna '{new_col}' adicionada como match direto de '{ref_col}' por similaridade de nome = 1")

            if types_compatible and not null_types:
            #  or value_number)
                data_similarity = 0
                if new_col in new_data.columns and ref_col in ref_data.columns:
                    if ref_col_type == "Data":
                        formated_new = new_data[new_col].str.replace(r'\D', '', regex=True)
                        formated_ref = ref_data[ref_col].str.replace(r'\D', '', regex=True)

                        year_new = year_evaluation(new_data[new_col])
                        year_ref = year_evaluation(ref_data[ref_col])

                        # MÃ©dia das diferenÃ§as formatada pelo ano atual
                        data_age = (100 - (abs(year_new - year_ref))) / 100

                        variation_new = date_var(formated_new)
                        variation_ref = date_var(formated_ref)

                        if isinstance(variation_new, pd.Series):
                            variation_new = variation_new.mean()
                        if isinstance(variation_ref, pd.Series):
                            variation_ref = variation_ref.mean()

                        scaling_factor = 0.3  # ajustar esse valor conforme necessÃ¡rio
                        variation_diff = abs(variation_new - variation_ref)

                        # Normaliza entre 0 e 1
                        variation_score = 1 - ((variation_diff * scaling_factor) / max(variation_new, variation_ref, 1))
                        # Combinar idade e variaÃ§Ã£o para calcular similaridade final
                        data_similarity = (data_age * 0.4) + (variation_score * 0.6)

                    elif ref_col_type_cleaned == "Valor":
                        data_similarity = 1

                    else:  #TODO add regra?
                        # Calcula a similaridade entre os dados e suas descriÃ§Ãµes (baseado em amostragem)
                        ref_data_emb = ref_data_desc[ref_col]
                        new_data_emb = new_data_desc[new_col]

                        data_similarity = util.cos_sim(ref_data_emb, new_data_emb).item()

                    print(f"{new_col} x {ref_col}: data similarity = {data_similarity:.2f}")

                if name_similarity == 1:
                    overall_score = (name_similarity * 0.7) + (data_similarity * 0.3)
                else:
                    overall_score = (name_similarity * 0.25) + (data_similarity * 0.75)
                    # TODO verificar os pesos

                print(f"Score final: {ref_col} x {new_col} = {overall_score}")

                if overall_score >= threshold:
                    candidates.append((ref_col, new_col, overall_score))

    # âœ… ApÃ³s o loop: resolve matches com maior score, sem repetir colunas
    used_new_cols = set()
    matched_columns = {}

    candidates.sort(key=lambda x: x[2], reverse=True)

    for ref_col, new_col, score in candidates:
            if ref_col not in matched_columns and new_col not in used_new_cols:
                matched_columns[ref_col] = new_col
                used_new_cols.add(new_col)
                not_match_new.discard(new_col)
                not_match_ref.discard(ref_col)
                print(f"âœ… Coluna '{new_col}' foi renomeada para '{ref_col}' com score {score:.2f}")

    # ImpressÃ£o final
    print("\n\nCorrespondÃªncia de colunas concluÃ­da!\n\nMatchs realizados (definitivos):")
    for ref_col, new_col in matched_columns.items():
        print(f"{ref_col}: {new_col}")

    if not_match_ref:
        print(f"\nColunas sem correspondÃªncia em {filename1}: {not_match_ref}")
    if not_match_new:
        print(f"Colunas sem correspondÃªncia em {filename2}: {not_match_new}\n")

    return matched_columns

#---------------------------TRANSFORMAR OS DADOS DA TABELA NOVA---------------------------#
def format_range(value):
    if not isinstance(value, str) or len(value) < 2:
        return None, None  # Retorna valores nulos se o dado for invÃ¡lido

    # Remover sÃ­mbolos de moeda, espaÃ§os e caracteres nÃ£o numÃ©ricos (exceto "-" e "+")
    clean_value = re.sub(r'[^\d\-,+]', '', value)

    # Se o formato for "AtÃ© R$360.000"
    if "AtÃ©" in value or clean_value.startswith('-'):
        min_value = 0  # Define o mÃ­nimo como 0
        max_value = re.sub(r'\D', '', clean_value)  # MantÃ©m apenas nÃºmeros no mÃ¡ximo
        max_value = int(max_value)
        return int(min_value), max_value if max_value else None

    # Se for um range no formato "R$360.000 - R$4.800.000"
    elif '-' in clean_value:
        min_value, max_value = clean_value.split('-')
        min_value = re.sub(r'\D', '', min_value)
        max_value = re.sub(r'\D', '', max_value)
        min_value = int(min_value) if min_value else None
        max_value = int(max_value) if max_value else None
        return min_value, max_value

    # Se for um valor aberto como "R$10.000.000.000 +"
    elif "+" in clean_value:
        min_value = re.sub(r'\D', '', clean_value)
        min_value = int(min_value) if min_value else None
        max_value = 999999999999999  # Define o mÃ¡ximo fixo como 999999999999999
        return min_value, max_value

    return None, None  # Caso nÃ£o caia em nenhum formato esperado


def transform_value(new_data, matched_columns, unique_values, ref_list, ref_types):
    # # Filtrar os itens que possuem "Valor (range)" na coluna "Tipo"
    # print(f"Matched columns: {matched_columns}. \nmatched_columns:: {type(matched_columns)}")
    # print(f"Unique values: {unique_values}. \nunique_values: {type(unique_values)}")
    # print(f"Ref list: {ref_list}. \nref_list: {type(ref_list)}")
    # print(f"Ref types: {ref_types}. \nref_types: {type(ref_types)}")

    print("Transformando valores tipo range")
    range_columns = ref_types[ref_types['Tipo'].isin(['Valor (range)', 'NÃºmero (range)'])]['Coluna']
    # print(f"Range columns: {range_columns}")

    # print(f"Colunas: {range_columns}")

    result_df = pd.DataFrame()

    for column in range_columns:
        if column in ref_list:
            # print(f"Coluna {column} estÃ¡ na lista de drop down")
            # print(f"Coluna {column} presente na lista de colunas")
            # Buscar os valores associados em unique_values
            # print(unique_values)
            if column in unique_values:
                # print(f"Coluna {column} estÃ¡ no dicionario")
                # print(f"Coluna {column} presente no dicionario de valores Ãºnicos")
                # unique_df = pd.DataFrame(unique_values[column], columns=[column])
                unique_df = pd.DataFrame(unique_values.get(column, []), columns=[column])
                # print(f"Unique df: {unique_df}")

                # Se unique_df estiver vazio, imprimir aviso
                if unique_df.empty:
                    print(f"âš ï¸ Aviso: Nenhum valor encontrado em unique_values para {column}. Pulando...")
                    continue

                    # Criar colunas de mÃ­nimo e mÃ¡ximo
                unique_df[[f"{column} - Min", f"{column} - Max"]] = (
                    unique_df[column]
                    .apply(lambda x: format_range(x))  # Retorna (Min, Max)
                    .apply(pd.Series)
                )
                # print(f"Unique df min e max: {unique_df}")
                # # Criar colunas de mÃ­nimo e mÃ¡ximo
                # unique_df[[f"{column} - Min", f"{column} - Max"]] = unique_df[column].apply(lambda x: format_range(x)).apply(pd.Series)
                # print(f"DF com os valores transformados: \n{unique_df}")

                # Se `format_range` nÃ£o estiver funcionando corretamente, pode retornar colunas vazias
                if unique_df[[f"{column} - Min", f"{column} - Max"]].isnull().all().all():
                    print(f"âš ï¸ Aviso: Todos os valores em {column} - Min e {column} - Max sÃ£o NaN.")
                    continue  # Evita continuar se os valores forem invÃ¡lidos

                # Armazenar o resultado
                # result_df = pd.concat([result_df, unique_df], axis=0)
                # print(f"DF resultante: \n{result_df}")

                result_df = pd.concat([result_df, unique_df], axis=0).reset_index(drop=True)
                # print(f"Result df: {result_df}")
                # print(f"âœ”ï¸ Intervalos para {column} gerados:\n{unique_df}")

            if column in matched_columns:
                # print(f"Coluna {column} presente no dicionario de matches")
                mapped_column = matched_columns[column]
                if mapped_column in new_data:
                    # print(f"ğŸ”¹ Aplicando transformaÃ§Ã£o na coluna correspondente: {mapped_column}")

                    # âœ… Verificar se as colunas existem antes de acessÃ¡-las
                    if f"{column} - Min" not in result_df.columns or f"{column} - Max" not in result_df.columns:
                        print(f"âš ï¸ Aviso: Colunas {column} - Min e {column} - Max nÃ£o encontradas. Pulando...")
                        continue  # Evita erro de KeyError

                    # Converter para numÃ©rico
                    def convert_to_number(value):
                        # Substitui vÃ­rgula por ponto para conversÃ£o correta
                        value = str(value).replace(",", ".")

                        # Verifica se Ã© um nÃºmero puro
                        if value.replace(".", "", 1).isdigit():  # Permite apenas um ponto decimal
                            return float(value)

                        # Se for um intervalo "X-Y", calcular a mÃ©dia
                        if "-" in value:
                            parts = value.split("-")
                            try:
                                num1 = float(parts[0].strip())
                                num2 = float(parts[1].strip())
                                return (num1 + num2) / 2  # MÃ©dia dos dois nÃºmeros
                            except ValueError:
                                return np.nan  # Caso algum valor nÃ£o seja numÃ©rico, retorna NaN

                        return np.nan  # Caso nÃ£o seja possÃ­vel converter

                    new_data[mapped_column] = new_data[mapped_column].apply(convert_to_number)

                    # print(f"New data: {new_data[mapped_column]}")

                    def map_value(x):
                        if pd.notnull(x):  # Evita erros com valores nulos
                            row = result_df[
                                (result_df[f"{column} - Min"] <= x) &
                                (result_df[f"{column} - Max"] >= x)
                                ]
                            # print(f"Row: {row}")
                            return row[column].values[0] if not row.empty else None
                        return None

                    # ğŸ”¹ Substituir a coluna original
                    new_data[mapped_column] = new_data[mapped_column].apply(map_value)
                    # print(f"New data: \n{new_data[mapped_column]}")
                    # print(f"âœ”ï¸ TransformaÃ§Ã£o aplicada para {mapped_column}")
                    # print(new_data)

    return new_data

def transform_data(ref_data, new_data, matched_columns):
    print("\nğŸ“ Iniciando transformaÃ§Ã£o das colunas...")

    # 1. Renomeia as colunas de new_data com base no dicionÃ¡rio:
    print("ğŸ”„ Renomeando colunas com base no dicionÃ¡rio de correspondÃªncias...")
    renamed_columns = {v: k for k, v in matched_columns.items() if v in new_data.columns}
    print(f"ğŸ“Œ Colunas renomeadas: {renamed_columns}")
    transformed_data = new_data.rename(columns=renamed_columns).copy()
    print(f"dados transformados de new_data: \n{transformed_data}")

    # 2. Remover colunas extras em `transformed_data` que nÃ£o existem em `ref_data`
    print("ğŸ—‘ï¸ Removendo colunas que nÃ£o existem na referÃªncia...")
    extra_cols = [col for col in transformed_data.columns if col not in ref_data.columns]
    print(f"âŒ Colunas removidas: {extra_cols}")
    transformed_data = transformed_data.loc[:, transformed_data.columns.isin(ref_data.columns)].copy()

    # 3. Adicionar colunas ausentes em `transformed_data`, preenchendo com ""
    print("â• Adicionando colunas ausentes...")
    missing_cols = set(ref_data.columns) - set(transformed_data.columns)
    print(f"âœ… Colunas adicionadas (preenchidas com ''): {missing_cols}")
    for col in missing_cols:
        transformed_data[col] = ""  # Adicionando colunas ausentes

    # ğŸš¨ Verificar colunas duplicadas antes de reindexar
    print("ğŸ” Verificando colunas duplicadas...")
    duplicated_cols = transformed_data.columns[transformed_data.columns.duplicated()]
    if not duplicated_cols.empty:
        print(f"âš ï¸ Aviso: Colunas duplicadas detectadas e serÃ£o removidas: {list(duplicated_cols)}")
        transformed_data = transformed_data.loc[:, ~transformed_data.columns.duplicated()].copy()
    else:
        print("âœ… Nenhuma coluna duplicada encontrada.")

    # 4. Garantir que a ordem das colunas seja a mesma do `ref_data`
    print("ğŸ”„ Reorganizando as colunas para manter a mesma ordem da referÃªncia...")
    transformed_data = transformed_data.reindex(columns=ref_data.columns, fill_value="").copy()

    print("âœ… TransformaÃ§Ã£o de dados concluÃ­da!\n")
    return transformed_data

def validate_data(new_data, matched_columns, ref_unique_values, columns_list, threshold=0.6):
    for ref_col, new_col in matched_columns.items():
        if ref_col in columns_list:
            allowed_values = ref_unique_values.get(ref_col, [])

            if not allowed_values or not isinstance(allowed_values, list):
                print(f"Aviso: Valores Ãºnicos para '{ref_col}' nÃ£o encontrados ou invÃ¡lidos.")
                continue

            # Garante que allowed_values seja uma lista de strings
            allowed_values = [str(val).strip() for val in allowed_values]

            def find_best_match(value):
                if pd.isna(value) or value == "nan":  # Se for NaN, retorna vazio
                    return ""
                value = str(value).strip()  # Converte para string e remove espaÃ§os extras

                # ObtÃ©m a melhor correspondÃªncia e a pontuaÃ§Ã£o de similaridade
                best_match, score = process.extractOne(value, allowed_values)

                return best_match if score >= threshold else value  # Retorna o original se nÃ£o for prÃ³ximo o suficiente

            # Verifica se a coluna existe no DataFrame antes de aplicar a correÃ§Ã£o
            if new_col in new_data.columns:
                new_data[new_col] = new_data[new_col].astype(str).apply(find_best_match)
                print(f"Coluna '{new_col}' validada com base na referÃªncia '{ref_col}'.")
            else:
                print(f"Aviso: Coluna '{new_col}' nÃ£o encontrada no DataFrame.")

    return new_data

#---------------------------EXECUTAR PROCESSO COMPLETO---------------------------#
def main(ref_data_path, new_data_path, ref_filename, new_filename):
    try:
        ref_path = ref_filename
        new_path = new_filename

        start_time = time.time()

        # TODO esse ", dtype=str).dropna(how='all'" talvez tenha que tirar
        print("Carregando arquivos CSV...")
        ref_data = pd.read_csv(ref_data_path, dtype=str).dropna(how='all')
        new_data = pd.read_csv(new_data_path, dtype=str).dropna(how='all')

        print("ğŸ“Š Analisando tipos de tabela...")
        ref_df = classificar_df(ref_data)
        new_df = classificar_df(new_data)
        if ref_df == new_df:
            print(
                f"\nâœ… ComparaÃ§Ã£o entre tipos de tabela OK: \nâ†’ Tabela {ref_path} = {ref_df} \nâ†’ Tabela {new_path} = {new_df}\n")

            # TODO ver se pode manter
            print("Avaliando listas suspensas na tabela de referÃªncia")
            ref_data, ref_dd_list = dd_list_columns(ref_data)
            print(f"Lista de colunas drop down: \n{ref_dd_list}")

            print("\nğŸ“Š Analisando tipos de dados...")
            # ğŸ”¹ Executa a funÃ§Ã£o apenas uma vez e armazena os retornos
            df_ref, ref_types, unique_values_dict_ref = analyze_table(ref_data, ref_path)
            df_new, new_types, _ = analyze_table(new_data, new_path)

            matched_columns = match_columns(df_ref, df_new, ref_types, new_types, ref_path, new_path)
            df_new = transform_value(df_new, matched_columns, unique_values_dict_ref, ref_dd_list, ref_types)

            validated_data = validate_data(df_new, matched_columns, unique_values_dict_ref, ref_dd_list)

            transformed_data = transform_data(df_ref, validated_data, matched_columns)
            # TODO ver se precisa disso
            transformed_data = transformed_data.astype(str)
            # Substituir todas as ocorrÃªncias da string "NaN" por valores vazios (sem inplace=True)
            transformed_data.replace("nan", "", inplace=True)
            transformed_data.replace("None", "", inplace=True)

            # Converte o DataFrame para JSON (uma lista de registros)
            json_data = transformed_data.to_json(orient='records')
            print("âœ… Dados transformados preparados para API")

            end_time = time.time()

            elapsed_time = end_time - start_time
            print(f"â±ï¸ Tempo de execuÃ§Ã£o: {elapsed_time:.2f} segundos")
            return json_data
        else:
            print(f"Tabelas nÃ£o correspondem.\nTabela {ref_data} = {ref_df}. Tabela {new_data} = {new_df}")

    except Exception as e:
        return {"error": str(e)}